# Octo

## 背景
在 RT 系列和 RT-X (Open X-Embodiment) 的推动下，机器人研究已经验证了“大规模数据 + Transformer”在提升泛化能力方面的价值。  
但问题依然存在：
- 早期模型（RT-1/RT-2）没有公开权重，学术界难以复现。  
- 跨平台数据（RT-X）虽然庞大，但模型并未完全开源，缺乏可直接使用的基座。  
- 高算力需求使研究者难以在消费级 GPU 上进行实验。  

**Octo 的动机**：打造一个**开源、可扩展、可快速微调**的通用机器人策略模型，让学术界和工业界都能方便地复用。

---

## 方法与架构
- **输入模态**：
  - **自然语言指令**（如 "stack the red block on the blue block"）。  
  - **目标图像**（goal image），为模型提供明确的视觉目标。  
- **模型架构**：
  - **Transformer 编码器-解码器**，用于融合语言与视觉表征。  
  - **多模态感知**：支持 RGB 图像、目标图像，以及其他可能的传感输入。  
  - **动作预测头**：输出离散化动作 token，覆盖末端执行器 6DoF 和 gripper 控制。  
- **训练方式**：
  - 在 ~80 万条机器人演示数据上进行预训练。  
  - 数据来源多样，包括真实机器人与仿真。  

---

## 技术细节
- **数据规模**：约 **800,000** 演示，比 RT-1 (130k) 大几个数量级。  
- **任务覆盖**：抓取、搬运、堆叠、开关、分类等广泛 manipulation。  
- **动作表示**：基于离散化 token 的自回归预测，延续 RT 系列方法。  
- **微调能力**：
  - 提供 **LoRA/PEFT** 支持，使得模型可以在 **单张消费级 GPU (24GB VRAM)** 上快速适配。  
  - 微调仅需数千条演示即可取得良好性能。  
- **评测**：
  - Octo 在跨任务、跨环境的测试中表现出稳定的迁移能力。  

---

## 局限性
- **任务复杂性不足**：虽然数据量大，但大多数任务仍然是短时、低复杂度的 manipulation。  
- **动作空间限制**：采用离散 token 输出，可能难以处理需要高精度控制的任务（如柔性物体操作）。  
- **硬件多样性有限**：数据虽多，但主要集中在少数几种机器人平台，真正的跨硬件泛化仍未充分验证。  
- **推理延迟**：在实时机器人控制中，推理速度仍是瓶颈。  

---

## 意义
- **开源里程碑**：Octo 是第一个 **完全开源** 的大规模 VLA 模型，标志着通用机器人策略从封闭走向开放。  
- **研究便利性**：研究者可直接下载模型，在消费级 GPU 上运行与微调，极大降低了入门门槛。  
- **推动生态**：Octo 为机器人领域带来了类似 NLP 中 Hugging Face Transformers 的“基座模型”作用。  
- **学术价值**：提供了一个可复现实验基准，加速了 VLA 社区在动作标记化、参数高效微调和高效推理等方面的研究。  

---

## 参考文献
- Team Octo, *Octo: An Open-Source Generalist Robot Policy*, arXiv 2024.  
