# 动作标记化（Action Tokenization）

## 背景
在机器人学习中，动作（action）通常是 **连续控制信号**（如关节角度、末端执行器位姿、力/力矩）。  
然而，这些原始信号难以与 **语言 token** 或 **视觉 token** 对齐。  

**为什么需要动作标记化？**
- 统一表示：如果动作也能被转化为 token，那么语言、视觉、行动都能在同一个 Transformer 中处理。  
- 学习稳定性：连续动作空间维度高，训练容易发散；通过离散化可以降低学习难度。  
- 泛化与压缩：token 化能捕捉任务的高层语义（如“抓取”），而不是仅仅低层数值。  

---

## 方法

### （入门版解释）
想象机器人要学会“写字”：  
- **连续控制**：告诉它每个手指的角度和速度，复杂且难学。  
- **离散 token**：把“写字”拆成一系列小动作（拿笔 → 放下 → 移动 → 抬起），就像文字一样逐个拼接。  
- **动作标记化**就是把复杂的连续控制，变成类似“词语”的单位，方便机器人理解和组合。

---

### （技术细节版）
常见方法包括：

1. **离散动作 token**  
   - 将连续控制信号量化成有限集合。  
   - 示例：RT-1 将末端执行器的 6DoF 位姿 + gripper 控制离散化为 token 序列，通过自回归 Transformer 预测。  
   - 优点：易与语言 token 对齐，训练稳定。  
   - 缺点：分辨率受限，精度损失。  

2. **运动原语 / 子目标**  
   - 将复杂动作分解为一系列 **高层原语**（如“抓取”、“移动”、“放置”）。  
   - 示例：CALVIN 基准中使用子目标表示长时序任务。  
   - 优点：可解释性强，泛化能力好。  
   - 缺点：需要人工设计或额外学习原语。  

3. **程序化表示**  
   - 将动作表示为可执行的 **代码/程序**（如条件语句、循环、函数调用）。  
   - 示例：Code-as-Policies (CaP) 将语言翻译为机器人可执行的代码。  
   - 优点：灵活性强，支持任务组合。  
   - 缺点：需要运行时解释器，执行效率受限。  

4. **混合自回归方案**  
   - 结合离散与连续：用 token 表示大部分结构，用连续数值填充细节。  
   - 示例：一些近期 VLA 模型在规划阶段使用 token，在控制阶段输出连续动作。  
   - 优点：兼顾精度与泛化。  
   - 缺点：训练与解码复杂度更高。  

---

## 使用案例
- **RT-1**：采用离散动作 token，使得语言+图像能直接映射到控制。  
- **RT-2**：在 RT-1 基础上，保持动作 token 化，增强语义泛化。  
- **Octo**：支持多模态输入（语言+目标图像），动作仍以 token 序列输出，便于快速微调。  
- **CALVIN**：强调基于子目标的任务分解，是动作原语方法的典型应用。  
- **CaP (Code-as-Policies)**：使用程序化表示，增强了任务的可组合性与可解释性。  

---

## 优缺点对比

| 方法 | 优点 | 缺点 | 代表性工作 |
|------|------|------|------------|
| 离散动作 token | 对齐语言，训练稳定 | 精度损失 | RT-1, RT-2 |
| 运动原语 / 子目标 | 可解释性强，泛化好 | 需要额外设计或学习 | CALVIN |
| 程序化表示 | 灵活，可组合 | 执行效率低 | CaP |
| 混合自回归 | 精度与泛化兼顾 | 复杂度高 | 新一代 VLA 模型探索中 |

---

## 意义
- **方法论价值**：动作标记化是 VLA 模型的核心问题之一，直接决定了模型能否在同一框架下处理语言、视觉与行动。  
- **工程价值**：离散 token 化和原语化能显著降低训练与推理开销，使模型更易在消费级硬件上运行。  
- **研究前景**：未来可能发展出 **层级动作 token 化**（高层 token 表示语义，低层 token 表示精确控制），结合 PEFT 与高效推理方法，支持更复杂的长时序机器人任务。  
